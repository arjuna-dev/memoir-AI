# MemoirAI Development Guide

## Project Structure

```
memoir-ai/
â”œâ”€â”€ memoir_ai/              # Main package
â”‚   â”œâ”€â”€ __init__.py         # Package exports
â”‚   â”œâ”€â”€ core.py             # Main MemoirAI class
â”‚   â”œâ”€â”€ models.py           # Data models and types
â”‚   â”œâ”€â”€ exceptions.py       # Custom exceptions
â”‚   â””â”€â”€ config.py           # Configuration management
â”œâ”€â”€ tests/                  # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_config.py      # Configuration tests
â”œâ”€â”€ examples/               # Usage examples
â”‚   â””â”€â”€ basic_usage.py      # Basic usage demonstration
â”œâ”€â”€ pyproject.toml          # Project metadata
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ Makefile                # Development commands
â””â”€â”€ .pre-commit-config.yaml # Code quality hooks
```

## Completed Features âœ…

### Task 1: Project Structure and Core Dependencies

- âœ… Python package structure with uv-based dependency workflow
- âœ… Core dependencies: SQLAlchemy, Pydantic AI, liteLLM, asyncio support
- âœ… Development dependencies: pytest, black, mypy, pre-commit hooks
- âœ… Configuration management for database and LLM settings
- âœ… Comprehensive configuration validation with clear error messages
- âœ… Environment variable support for all major settings
- âœ… Basic test suite with 9 passing tests

### Task 2.1: SQLAlchemy Database Models

- âœ… Category model with hierarchy constraints and validation
- âœ… Chunk model with token counting and source tracking
- âœ… ContextualHelper model for source context storage
- âœ… CategoryLimits model for configurable category limits per level
- âœ… All required indexes and constraints as specified in design
- âœ… Comprehensive model validation with clear error messages
- âœ… Database manager with connection pooling and retry logic
- âœ… Multi-database support (SQLite, PostgreSQL, MySQL configuration)
- âœ… Transaction management and error recovery
- âœ… 28 passing tests covering all database functionality

### Task 2.2: Database Migration and Initialization System

- âœ… Alembic migration setup for schema versioning
- âœ… Database initialization logic that auto-creates tables and indexes
- âœ… Database connection management with retry logic and error handling
- âœ… Migration tracking and validation system
- âœ… Database reset and schema validation functionality
- âœ… Integration with MemoirAI core class for automatic initialization
- âœ… Comprehensive migration manager with error recovery
- âœ… 37+ passing tests covering all migration functionality

### Task 3.1: Token-Based Text Chunker

- âœ… TextChunker class using liteLLM's token_counter function
- âœ… Configurable delimiters and token size thresholds (300-500 tokens default)
- âœ… Paragraph boundary preservation logic with configurable options
- âœ… Chunk merging for undersized chunks and splitting for oversized chunks
- âœ… Comprehensive validation and error handling with clear messages
- âœ… Multi-model token counting support (GPT, Claude, etc.)
- âœ… Unicode and special character support
- âœ… Integration with MemoirAI core class for seamless usage
- âœ… 25+ passing tests covering all chunking functionality and edge cases

### Configuration Validation Features

- âœ… Token budget vs chunk size constraint validation
- âœ… Hierarchy depth validation (1-100 levels)
- âœ… Batch size validation (1-50)
- âœ… Category limits validation (global and per-level)
- âœ… Database URL format validation
- âœ… LLM provider and model validation
- âœ… Clear error messages with suggested fixes

### Code Quality Setup

- âœ… Black code formatting
- âœ… MyPy type checking
- âœ… Pre-commit hooks configuration
- âœ… Comprehensive test coverage
- âœ… Development Makefile with common tasks

## Next Steps ðŸš€

The foundation is now solid and ready for implementing core features:

1. **Database Layer** (Task 2.1-2.2)

   - SQLAlchemy models for categories, chunks, contextual helpers
   - Database migration and initialization system
   - Multi-database backend support

2. **Text Processing** (Task 3.1-3.2)

   - Token-based text chunker using liteLLM
   - Contextual helper generation system
   - Paragraph boundary preservation

3. **LLM Integration** (Task 4.1-4.2)
   - Pydantic AI schemas and agents
   - Batch classification system
   - Native structured output support

## Development Commands

```bash
# Create virtual environment (one-time)
uv venv .venv

# Install dev dependencies and pre-commit hooks
make dev-setup

# Run tests
make test

# Run example script
UV_PROJECT_ENVIRONMENT=.venv UV_NO_PROJECT=1 uv run python examples/basic_usage.py

# Format code
make format

# Run linting
make lint
```

## Configuration Examples

```python
# Basic configuration
memoir = MemoirAI(
    database_url="sqlite:///memoir.db",
    llm_provider="openai",
    model_name="gpt-4"
)

# Advanced configuration
memoir = MemoirAI(
    database_url="postgresql://user:pass@localhost/memoir",
    hierarchy_depth=5,
    chunk_min_tokens=200,
    chunk_max_tokens=800,
    batch_size=10,
    max_categories_per_level={1: 20, 2: 50, 3: 100},
    max_token_budget=8000
)
```

## Environment Variables

```bash
export MEMOIR_DATABASE_URL="sqlite:///memoir.db"
export MEMOIR_LLM_PROVIDER="openai"
export MEMOIR_MODEL_NAME="gpt-4"
export MEMOIR_HIERARCHY_DEPTH="3"
export MEMOIR_BATCH_SIZE="5"
export MEMOIR_MAX_TOKEN_BUDGET="4000"
```

The project foundation is complete and ready for core feature implementation! ðŸŽ‰
